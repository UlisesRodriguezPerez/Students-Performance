{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis del Rendimiento de Estudiantes\n",
    "\n",
    "## Introducción\n",
    "\n",
    "Este proyecto se centra en analizar el rendimiento de estudiantes en tres áreas clave: matemáticas, lectura y escritura, utilizando el dataset 'Students Performance'. El objetivo es explorar cómo diversas características demográficas y socioeconómicas, como el género, el grupo étnico y el nivel educativo de los padres, influyen en el rendimiento académico de los estudiantes.\n",
    "\n",
    "A través de este análisis, buscamos identificar patrones significativos y factores predictivos que puedan ayudar en la formulación de estrategias para mejorar el rendimiento estudiantil. Las principales tareas incluirán la exploración de datos, visualización, manejo de datos faltantes, análisis estadístico y modelado predictivo para estimar el rendimiento en matemáticas.\n",
    "\n",
    "Este análisis no solo aportará insights valiosos sobre la educación sino que también demostrará cómo técnicas avanzadas de análisis de datos pueden aplicarse en contextos educativos para obtener conclusiones prácticas y útiles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de Datos\n",
    "A continuación, cargamos el dataset utilizando la librería Pandas. Contiene las siguientes columnas de interés:\n",
    "- `gender`: Género del estudiante.\n",
    "- `race/ethnicity`: Grupo étnico del estudiante.\n",
    "- `parental level of education`: Nivel educativo de los padres.\n",
    "- `lunch`: Tipo de almuerzo.\n",
    "- `test preparation course`: Si el estudiante tomó o no un curso de preparación.\n",
    "- `math score`, `reading score`, `writing score`: Puntuaciones en las pruebas de matemáticas, lectura y escritura.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data_path = '../data/StudentsPerformance.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Show the first rows of the dataframe using the head method\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General information about the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for the numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "#check for missing values and handle them if any\n",
    "if df.isnull().sum().any():\n",
    "    # fill missing values with the mean when the column is numerical and with the mode when the column is categorical\n",
    "    df.fillna({\n",
    "        'math score': df['math score'].mean(),\n",
    "        'reading score': df['reading score'].mean(),\n",
    "        'writing score': df['writing score'].mean(),\n",
    "        'gender': df['gender'].mode()[0],\n",
    "        'race/ethnicity': df['race/ethnicity'].mode()[0],\n",
    "        'parental level of education': df['parental level of education'].mode()[0],\n",
    "        'lunch': df['lunch'].mode()[0],\n",
    "        'test preparation course': df['test preparation course'].mode()[0]\n",
    "    }, inplace=True)\n",
    "else:\n",
    "    print('No missing values found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Histogramas de las puntuaciones\n",
    "''' \n",
    "Utilizamos histogramas para visualizar la distribución de las puntuaciones en matemáticas, lectura y escritura. \n",
    "Estos gráficos nos permiten observar la forma de la distribución y detectar si existen patrones como asimetría o presencia de picos.\n",
    "\n",
    "'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Setting the style of seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Creating the histogram plots for the math, reading, and writing scores\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.histplot(df['math score'], kde=True, color='blue')\n",
    "plt.title('Distribución de Puntuaciones de Matemáticas')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.histplot(df['reading score'], kde=True, color='green')\n",
    "plt.title('Distribución de Puntuaciones de Lectura')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.histplot(df['writing score'], kde=True, color='red')\n",
    "plt.title('Distribución de Puntuaciones de Escritura')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gráficos de Caja por Género\n",
    "\n",
    "'''\n",
    "Los gráficos de caja proporcionan una forma visual de comparar la distribución de las puntuaciones entre diferentes grupos de género, destacando diferencias en medianas, rangos intercuartílicos y la presencia de valores atípicos.\n",
    "'''\n",
    "\n",
    "# Graphs of box plots to compare performance by gender\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(x='gender', y='math score', data=df)\n",
    "plt.title('Puntuaciones de Matemáticas por Género')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(x='gender', y='reading score', data=df)\n",
    "plt.title('Puntuaciones de Lectura por Género')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(x='gender', y='writing score', data=df)\n",
    "plt.title('Puntuaciones de Escritura por Género')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de caja del nivel educativo de los padres y las puntuaciones en todas las materias\n",
    "subjects = ['math score', 'reading score', 'writing score']\n",
    "titles = ['Matemáticas', 'Lectura', 'Escritura']\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "for i, (score, title) in enumerate(zip(subjects, titles), 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    sns.boxplot(x='parental level of education', y=score, data=df)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(f'Puntuaciones de {title} por Nivel Educativo de los Padres')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de caja de la relación entre el almuerzo y las puntuaciones en todas las materias\n",
    "plt.figure(figsize=(18, 6))\n",
    "for i, score in enumerate(subjects, 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    sns.boxplot(x='lunch', y=score, data=df)\n",
    "    plt.title(f'{score.title()} por Tipo de Almuerzo')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de caja de la relación entre la preparación del examen y las puntuaciones en todas las materias\n",
    "plt.figure(figsize=(18, 6))\n",
    "for i, score in enumerate(subjects, 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    sns.boxplot(x='test preparation course', y=score, data=df)\n",
    "    plt.title(f'{score.title()} por Preparación del Examen')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score_category'] = pd.cut(df['math score'], bins=[0, 50, 70, 100], labels=['Low', 'Medium', 'High'])\n",
    "plt.figure(figsize=(10, 6))\n",
    "(df.groupby(['gender', 'score_category']).size().unstack().apply(lambda x: x/x.sum(), axis=1).plot(kind='bar', stacked=True))\n",
    "plt.title('Distribución de Categorías de Puntuación en Matemáticas por Género')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gráficos de Dispersión entre Puntuaciones\n",
    "'''\n",
    "Utilizamos gráficos de dispersión para evaluar la relación entre las diferentes puntuaciones académicas. Estos gráficos ayudan a identificar correlaciones potenciales entre las puntuaciones en matemáticas, lectura y escritura.\n",
    "\n",
    "'''\n",
    "# Gráficos de dispersión entre las puntuaciones\n",
    "sns.pairplot(df[['math score', 'reading score', 'writing score']])\n",
    "plt.suptitle('Dispersión entre Puntuaciones', y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlaciones entre las puntuaciones\n",
    "correlation_matrix = df[['math score', 'reading score', 'writing score']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Matriz de Correlación entre Puntuaciones')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codification of categorical variables and division data\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "df_encoded = pd.get_dummies(df, columns=['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course'])\n",
    "\n",
    "X = df_encoded.drop(['math score', 'reading score', 'writing score'], axis=1)  # Delete other scores to focus on math score\n",
    "y = df_encoded['math score']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f\"Linear Regression Mean Squared Error: {mse}\")\n",
    "\n",
    "# Coefficients of the linear regression model\n",
    "importance = pd.DataFrame({\n",
    "    'Attribute': X_train.columns,\n",
    "    'Importance': model.coef_\n",
    "})\n",
    "importance = importance.sort_values(by='Importance', ascending=False)\n",
    "print(\"Linear Regression coefficient importance:\\n\", importance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(X)\n",
    "x_train_scaled, x_test_scaled = scaler.transform(X_train), scaler.transform(X_test)\n",
    "\n",
    "# Different values of alpha\n",
    "alpha_options = [0.001, 0.01, 0.1, 1, 10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge  Model\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "best_score = np.inf\n",
    "best_alpha = {}\n",
    "\n",
    "for alpha in alpha_options:\n",
    "    model = Ridge(alpha=alpha, random_state=42, max_iter=10000)\n",
    "    model.fit(x_train_scaled, y_train)\n",
    "    scores = cross_val_score(model, x_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    mean_mse = -scores.mean()\n",
    "    if mean_mse < best_score:\n",
    "        best_score = mean_mse\n",
    "        best_alpha = {'alpha': alpha}\n",
    "    print(f\"Alpha: {alpha}, Mean Squared Error: {mean_mse:.2f}\")\n",
    "\n",
    "print(f\"\\n\\nBest Alpha: {best_alpha['alpha']}, Best Mean Squared Error: {best_score:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso  Model\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "best_score = np.inf\n",
    "best_alpha = {}\n",
    "\n",
    "for alpha in alpha_options:\n",
    "    model = Lasso(alpha=alpha, random_state=42, max_iter=10000)\n",
    "    model.fit(x_train_scaled, y_train)\n",
    "    scores = cross_val_score(model, x_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    mean_mse = -scores.mean()\n",
    "    if mean_mse < best_score:\n",
    "        best_score = mean_mse\n",
    "        best_alpha = {'alpha': alpha}\n",
    "    print(f\"Alpha: {alpha}, Mean Squared Error: {mean_mse:.2f}\")\n",
    "\n",
    "print(f\"\\n\\nBest Alpha: {best_alpha['alpha']}, Best Mean Squared Error: {best_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# List of different settings for testing\n",
    "n_estimators_options = [100, 200, 300]\n",
    "max_features_options = ['sqrt', 'log2', None]\n",
    "max_depth_options = [10, 15, 20, None]\n",
    "\n",
    "best_score = np.inf\n",
    "\n",
    "# Test all the combinations\n",
    "for n_estimators in n_estimators_options:\n",
    "    for max_features in max_features_options:\n",
    "        for max_depth in max_depth_options:\n",
    "            model = RandomForestRegressor(n_estimators=n_estimators, max_features=max_features, max_depth=max_depth, random_state=42)\n",
    "            model.fit(X_train, y_train)\n",
    "            scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "            mean_mse = -scores.mean()\n",
    "\n",
    "            print(f\"Random Forest with n_estimators={n_estimators}, max_features={max_features}, max_depth={max_depth}: MSE={mean_mse:.2f}\")\n",
    "\n",
    "            # Guardar el mejor modelo\n",
    "            if mean_mse < best_score:\n",
    "                best_score = mean_mse\n",
    "                best_params = {'n_estimators': n_estimators, 'max_features': max_features, 'max_depth': max_depth}\n",
    "\n",
    "print(f\"Best MSE: {best_score:.2f} with parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import combinations\n",
    "\n",
    "def test_feature_combinations(df, target, max_features=3):\n",
    "    features = [col for col in df.columns if col != target]\n",
    "    results = []\n",
    "\n",
    "        # Create file to store the results \n",
    "    filename = f\"../Results/linear_regression_results_{max_features}_features.txt\"\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(\"Linear Regression Feature Combination Results\\n\\n\")\n",
    "        file.write(f\"Max Features: {max_features}\\n\")\n",
    "    \n",
    "    # Probar todas las combinaciones de características\n",
    "    for r in range(1, max_features + 1):\n",
    "        for subset in combinations(features, r):\n",
    "            X = df[list(subset)]\n",
    "            y = df[target]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            \n",
    "            # Entrenar el modelo de regresión lineal\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train, y_train)\n",
    "            predictions = model.predict(X_test)\n",
    "            mse = mean_squared_error(y_test, predictions)\n",
    "            \n",
    "            # Almacenar el subset, MSE, y una muestra de los valores reales vs. predichos\n",
    "            results.append({\n",
    "                'features': subset,\n",
    "                'mse': mse,\n",
    "                'sample_comparison': pd.DataFrame({'Actual': y_test[:5], 'Predicted': predictions[:5]}).to_string()\n",
    "            })\n",
    "\n",
    "    # Ordenar los resultados por MSE\n",
    "    results.sort(key=lambda x: x['mse'])\n",
    "\n",
    "    # invert the order to have the best MSE first\n",
    "    results = results[:50][::-1]\n",
    "    \n",
    "    # # Mostrar solo las mejores 100 combinaciones\n",
    "    # for result in results:\n",
    "    #     print(f\"Features: {result['features']}\")\n",
    "    #     print(f\"MSE: {result['mse']}\")\n",
    "    #     print(f\"Sample Comparison:\\n{result['sample_comparison']}\\n\")\n",
    "\n",
    "    # save the results to a file\n",
    "    with open(filename, 'a') as file:\n",
    "        for result in results:\n",
    "            file.write(f\"Features: {result['features']}\\n\")\n",
    "            file.write(f\"MSE: {result['mse']}\\n\")\n",
    "            file.write(f\"Sample Comparison:\\n{result['sample_comparison']}\\n\\n\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "test_feature_combinations(df_encoded, 'math score', max_features=2)\n",
    "test_feature_combinations(df_encoded, 'math score', max_features=3)\n",
    "test_feature_combinations(df_encoded, 'math score', max_features=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "\n",
    "def test_ridge_combinations(df, target, max_features=3, alpha_options=[0.001, 0.01, 0.1, 1, 10, 100]):\n",
    "    features = [col for col in df.columns if col != target]\n",
    "    results = []\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Create file to store the results \n",
    "    filename = f\"../Results/ridge_results_max_features_{max_features}.txt\"\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(\"Ridge Regression Analysis\\n\")\n",
    "        file.write(f\"Max Features: {max_features}\\n\")\n",
    "\n",
    "    \n",
    "    # Probar todas las combinaciones de características\n",
    "    for r in range(1, max_features + 1):\n",
    "        for subset in combinations(features, r):\n",
    "            X = df[list(subset)]\n",
    "            y = df[target]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            \n",
    "            # Escalar los datos\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            \n",
    "            # Evaluar diferentes alphas\n",
    "            for alpha in alpha_options:\n",
    "                model = Ridge(alpha=alpha, max_iter=10000)\n",
    "                model.fit(X_train_scaled, y_train)\n",
    "                predictions = model.predict(X_test_scaled)\n",
    "                mse = mean_squared_error(y_test, predictions)\n",
    "                scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "                mean_cv_mse = -np.mean(scores)\n",
    "                \n",
    "                # Almacenar los resultados\n",
    "                results.append({\n",
    "                    'features': subset,\n",
    "                    'alpha': alpha,\n",
    "                    'mse': mse,\n",
    "                    'mean_cv_mse': mean_cv_mse,\n",
    "                    'sample_comparison': pd.DataFrame({'Actual': y_test[:5], 'Predicted': predictions[:5]}).to_string()\n",
    "                })\n",
    "\n",
    "    \n",
    "    # Ordenar los resultados por MSE de validación cruzada\n",
    "    results.sort(key=lambda x: x['mean_cv_mse'])\n",
    "\n",
    "    results = results[:50][::-1]\n",
    "\n",
    "    # # Mostrar solo las mejores 100 combinaciones\n",
    "    # for result in results:\n",
    "    #     print(f\"Features: {result['features']}, Alpha: {result['alpha']}\")\n",
    "    #     print(f\"MSE: {result['mse']}, Mean CV MSE: {result['mean_cv_mse']}\")\n",
    "    #     print(f\"Sample Comparison:\\n{result['sample_comparison']}\\n\")\n",
    "\n",
    "    # Write the results to the file\n",
    "    with open(filename, 'a') as file:\n",
    "        for result in results:\n",
    "            file.write(f\"Features: {result['features']}, Alpha: {result['alpha']}\\n\")\n",
    "            file.write(f\"MSE: {result['mse']}, Mean CV MSE: {result['mean_cv_mse']}\\n\")\n",
    "            file.write(f\"Sample Comparison:\\n{result['sample_comparison']}\\n\\n\")\n",
    "\n",
    "\n",
    "test_ridge_combinations(df_encoded, 'math score', max_features=2, alpha_options=[0.001, 0.01, 0.1, 1, 10, 100])\n",
    "test_ridge_combinations(df_encoded, 'math score', max_features=3, alpha_options=[0.001, 0.01, 0.1, 1, 10, 100])\n",
    "test_ridge_combinations(df_encoded, 'math score', max_features=5, alpha_options=[0.001, 0.01, 0.1, 1, 10, 100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "\n",
    "def test_random_forest_combinations(df, target, max_features_comb=3):\n",
    "    features = [col for col in df.columns if col != target]\n",
    "    results = []\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Crear archivo para almacenar los resultados\n",
    "    filename = f\"../Results/random_forest_results_max_features_{max_features_comb}.txt\"\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(\"Random Forest Regression Analysis\\n\")\n",
    "        file.write(f\"Max Features for Combination Testing: {max_features_comb}\\n\")\n",
    "\n",
    "    # Opciones de configuración del Random Forest\n",
    "    n_estimators_options = [100, 200]\n",
    "    max_features_options = ['sqrt', 'log2', None]\n",
    "    max_depth_options = [10, 15, None]\n",
    "\n",
    "    # Probar todas las combinaciones de características\n",
    "    for r in range(1, max_features_comb + 1):\n",
    "        for subset in combinations(features, r):\n",
    "            X = df[list(subset)]\n",
    "            y = df[target]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "            # Escalar los datos\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            # Evaluar diferentes configuraciones del Random Forest\n",
    "            for n_estimators in n_estimators_options:\n",
    "                for max_features in max_features_options:\n",
    "                    for max_depth in max_depth_options:\n",
    "                        model = RandomForestRegressor(n_estimators=n_estimators, max_features=max_features, max_depth=max_depth, random_state=42)\n",
    "                        model.fit(X_train_scaled, y_train)\n",
    "                        predictions = model.predict(X_test_scaled)\n",
    "                        mse = mean_squared_error(y_test, predictions)\n",
    "                        scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "                        mean_cv_mse = -np.mean(scores)\n",
    "\n",
    "                        # Almacenar los resultados\n",
    "                        results.append({\n",
    "                            'features': subset,\n",
    "                            'n_estimators': n_estimators,\n",
    "                            'max_features': max_features,\n",
    "                            'max_depth': max_depth,\n",
    "                            'mse': mse,\n",
    "                            'mean_cv_mse': mean_cv_mse,\n",
    "                            'sample_comparison': pd.DataFrame({'Actual': y_test[:5], 'Predicted': predictions[:5]}).to_string()\n",
    "                        })\n",
    "\n",
    "    # Ordenar los resultados por MSE de validación cruzada\n",
    "    results.sort(key=lambda x: x['mean_cv_mse'])\n",
    "\n",
    "    # Escribir los resultados en el archivo y mostrar los 20 mejores\n",
    "    with open(filename, 'a') as file:\n",
    "        for result in results[:20]:\n",
    "            file.write(f\"Features: {result['features']}, Estimators: {result['n_estimators']}, Max Features: {result['max_features']}, Max Depth: {result['max_depth']}\\n\")\n",
    "            file.write(f\"MSE: {result['mse']}, Mean CV MSE: {result['mean_cv_mse']}\\n\")\n",
    "            file.write(f\"Sample Comparison:\\n{result['sample_comparison']}\\n\\n\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "test_random_forest_combinations(df_encoded, 'math score', max_features_comb=2)\n",
    "test_random_forest_combinations(df_encoded, 'math score', max_features_comb=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
