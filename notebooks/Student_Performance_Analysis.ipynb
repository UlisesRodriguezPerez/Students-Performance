{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis del Rendimiento de Estudiantes\n",
    "\n",
    "## Introducción\n",
    "\n",
    "Este proyecto se centra en analizar el rendimiento de estudiantes en tres áreas clave: matemáticas, lectura y escritura, utilizando el dataset 'Students Performance'. El objetivo es explorar cómo diversas características demográficas y socioeconómicas, como el género, el grupo étnico y el nivel educativo de los padres, influyen en el rendimiento académico de los estudiantes.\n",
    "\n",
    "A través de este análisis, buscamos identificar patrones significativos y factores predictivos que puedan ayudar en la formulación de estrategias para mejorar el rendimiento estudiantil. Las principales tareas incluirán la exploración de datos, visualización, manejo de datos faltantes, análisis estadístico y modelado predictivo para estimar el rendimiento en matemáticas.\n",
    "\n",
    "Este análisis no solo aportará insights valiosos sobre la educación sino que también demostrará cómo técnicas avanzadas de análisis de datos pueden aplicarse en contextos educativos para obtener conclusiones prácticas y útiles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de Datos\n",
    "A continuación, cargamos el dataset utilizando la librería Pandas. Contiene las siguientes columnas de interés:\n",
    "- `gender`: Género del estudiante.\n",
    "- `race/ethnicity`: Grupo étnico del estudiante.\n",
    "- `parental level of education`: Nivel educativo de los padres.\n",
    "- `lunch`: Tipo de almuerzo.\n",
    "- `test preparation course`: Si el estudiante tomó o no un curso de preparación.\n",
    "- `math score`, `reading score`, `writing score`: Puntuaciones en las pruebas de matemáticas, lectura y escritura.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data_path = '../data/StudentsPerformance.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Show the first rows of the dataframe using the head method\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploración de Datos\n",
    "Visualizamos información general del DataFrame para entender la estructura y los tipos de datos que contiene.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General information about the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadísticas Descriptivas\n",
    "Obtenemos estadísticas descriptivas para las columnas numéricas del DataFrame para tener una visión general de la distribución de los datos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for the numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manejo de Valores Faltantes\n",
    "Verificamos y manejamos los valores faltantes en el dataset, utilizando la media para las variables numéricas y la moda para las categóricas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "#check for missing values and handle them if any\n",
    "if df.isnull().sum().any():\n",
    "    # fill missing values with the mean when the column is numerical and with the mode when the column is categorical\n",
    "    df.fillna({\n",
    "        'math score': df['math score'].mean(),\n",
    "        'reading score': df['reading score'].mean(),\n",
    "        'writing score': df['writing score'].mean(),\n",
    "        'gender': df['gender'].mode()[0],\n",
    "        'race/ethnicity': df['race/ethnicity'].mode()[0],\n",
    "        'parental level of education': df['parental level of education'].mode()[0],\n",
    "        'lunch': df['lunch'].mode()[0],\n",
    "        'test preparation course': df['test preparation course'].mode()[0]\n",
    "    }, inplace=True)\n",
    "else:\n",
    "    print('No missing values found')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de Distribuciones\n",
    "Utilizamos histogramas para examinar la distribución de las puntuaciones en matemáticas, lectura y escritura.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Histogramas de las puntuaciones\n",
    "''' \n",
    "Utilizamos histogramas para visualizar la distribución de las puntuaciones en matemáticas, lectura y escritura. \n",
    "Estos gráficos nos permiten observar la forma de la distribución y detectar si existen patrones como asimetría o presencia de picos.\n",
    "\n",
    "'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Setting the style of seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Creating the histogram plots for the math, reading, and writing scores\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.histplot(df['math score'], kde=True, color='blue')\n",
    "plt.title('Distribución de Puntuaciones de Matemáticas')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.histplot(df['reading score'], kde=True, color='green')\n",
    "plt.title('Distribución de Puntuaciones de Lectura')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.histplot(df['writing score'], kde=True, color='red')\n",
    "plt.title('Distribución de Puntuaciones de Escritura')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos de Caja por Género\n",
    "Analizamos las diferencias en las puntuaciones por género a través de gráficos de caja, los cuales ayudan a identificar variaciones en medianas y la presencia de valores atípicos entre grupos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gráficos de Caja por Género\n",
    "\n",
    "'''\n",
    "Los gráficos de caja proporcionan una forma visual de comparar la distribución de las puntuaciones entre diferentes grupos de género, destacando diferencias en medianas, rangos intercuartílicos y la presencia de valores atípicos.\n",
    "'''\n",
    "\n",
    "# Graphs of box plots to compare performance by gender\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(x='gender', y='math score', data=df)\n",
    "plt.title('Puntuaciones de Matemáticas por Género')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(x='gender', y='reading score', data=df)\n",
    "plt.title('Puntuaciones de Lectura por Género')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(x='gender', y='writing score', data=df)\n",
    "plt.title('Puntuaciones de Escritura por Género')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Influencia del Nivel Educativo de los Padres\n",
    "Exploramos cómo el nivel educativo de los padres afecta las puntuaciones en diferentes materias mediante gráficos de caja.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de caja del nivel educativo de los padres y las puntuaciones en todas las materias\n",
    "subjects = ['math score', 'reading score', 'writing score']\n",
    "titles = ['Matemáticas', 'Lectura', 'Escritura']\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "for i, (score, title) in enumerate(zip(subjects, titles), 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    sns.boxplot(x='parental level of education', y=score, data=df)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(f'Puntuaciones de {title} por Nivel Educativo de los Padres')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relación entre el Tipo de Almuerzo y las Puntuaciones\n",
    "Observamos cómo el tipo de almuerzo que los estudiantes reciben está relacionado con sus puntuaciones académicas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de caja de la relación entre el almuerzo y las puntuaciones en todas las materias\n",
    "plt.figure(figsize=(18, 6))\n",
    "for i, score in enumerate(subjects, 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    sns.boxplot(x='lunch', y=score, data=df)\n",
    "    plt.title(f'{score.title()} por Tipo de Almuerzo')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impacto de la Preparación para el Examen\n",
    "Evaluamos cómo la preparación para el examen influye en las puntuaciones utilizando gráficos de caja.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de caja de la relación entre la preparación del examen y las puntuaciones en todas las materias\n",
    "plt.figure(figsize=(18, 6))\n",
    "for i, score in enumerate(subjects, 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    sns.boxplot(x='test preparation course', y=score, data=df)\n",
    "    plt.title(f'{score.title()} por Preparación del Examen')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de Correlación entre Materias\n",
    "Utilizamos gráficos de dispersión para evaluar las relaciones entre las puntuaciones de diferentes materias y detectar correlaciones potenciales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gráficos de Dispersión entre Puntuaciones\n",
    "'''\n",
    "Utilizamos gráficos de dispersión para evaluar la relación entre las diferentes puntuaciones académicas. Estos gráficos ayudan a identificar correlaciones potenciales entre las puntuaciones en matemáticas, lectura y escritura.\n",
    "\n",
    "'''\n",
    "# Gráficos de dispersión entre las puntuaciones\n",
    "sns.pairplot(df[['math score', 'reading score', 'writing score']])\n",
    "plt.suptitle('Dispersión entre Puntuaciones', y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Correlación entre Puntuaciones\n",
    "Visualizamos la matriz de correlación para entender mejor las interrelaciones entre las diferentes puntuaciones académicas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlaciones entre las puntuaciones\n",
    "correlation_matrix = df[['math score', 'reading score', 'writing score']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Matriz de Correlación entre Puntuaciones')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de Datos\n",
    "Antes de construir modelos predictivos, es esencial preparar los datos adecuadamente. Este paso incluye la codificación de variables categóricas y la división de los datos en conjuntos de entrenamiento y prueba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Codification of categorical variables and division data\n",
    "df_encoded = pd.get_dummies(df, columns=['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course'])\n",
    "\n",
    "X = df_encoded.drop(['math score', 'reading score', 'writing score'], axis=1)  # Delete other scores to focus on math score\n",
    "y = df_encoded['math score']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Regresión Lineal\n",
    "Construimos un modelo de regresión lineal para predecir las puntuaciones de matemáticas. Evaluamos el modelo utilizando el error cuadrático medio (MSE) y validación cruzada para asegurar la robustez de nuestro modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(f'Cross-validation Mean Squared Error: {scores.mean() * -1}')\n",
    "\n",
    "# Feature importance\n",
    "importance = model.coef_\n",
    "feature_names = X.columns\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importance\n",
    "})\n",
    "\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "print(feature_importance)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de Datos para Modelos Regularizados\n",
    "Antes de aplicar modelos regularizados como Ridge y Lasso, es crucial estandarizar los datos para mejorar la eficiencia y efectividad de la regularización.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(X)\n",
    "x_train_scaled, x_test_scaled = scaler.transform(X_train), scaler.transform(X_test)\n",
    "\n",
    "# Different values of alpha\n",
    "alpha_options = [0.001, 0.01, 0.1, 1, 10, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Ridge\n",
    "Exploramos el uso del modelo Ridge, que incluye una regularización L2, para entender su impacto en el sobreajuste y seleccionar el mejor valor de alpha utilizando validación cruzada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge  Model\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "best_score = np.inf\n",
    "best_alpha = {}\n",
    "\n",
    "for alpha in alpha_options:\n",
    "    model = Ridge(alpha=alpha, random_state=42, max_iter=10000)\n",
    "    model.fit(x_train_scaled, y_train)\n",
    "    scores = cross_val_score(model, x_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    mean_mse = -scores.mean()\n",
    "    if mean_mse < best_score:\n",
    "        best_score = mean_mse\n",
    "        best_alpha = {'alpha': alpha}\n",
    "    print(f\"Alpha: {alpha}, Mean Squared Error: {mean_mse:.2f}\")\n",
    "\n",
    "print(f\"\\n\\nBest Alpha: {best_alpha['alpha']}, Best Mean Squared Error: {best_score:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Lasso\n",
    "El modelo Lasso incorpora una regularización L1, que puede ayudar a realizar la selección de características al penalizar los coeficientes de manera que algunos se reduzcan a cero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso  Model\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "best_score = np.inf\n",
    "best_alpha = {}\n",
    "\n",
    "for alpha in alpha_options:\n",
    "    model = Lasso(alpha=alpha, random_state=42, max_iter=10000)\n",
    "    model.fit(x_train_scaled, y_train)\n",
    "    scores = cross_val_score(model, x_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    mean_mse = -scores.mean()\n",
    "    if mean_mse < best_score:\n",
    "        best_score = mean_mse\n",
    "        best_alpha = {'alpha': alpha}\n",
    "    print(f\"Alpha: {alpha}, Mean Squared Error: {mean_mse:.2f}\")\n",
    "\n",
    "print(f\"\\n\\nBest Alpha: {best_alpha['alpha']}, Best Mean Squared Error: {best_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Random Forest\n",
    "Utilizamos un modelo Random Forest para evaluar cómo los métodos de ensamble pueden mejorar la predicción. Este modelo es especialmente útil para manejar interacciones complejas entre características y no linealidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# List of different settings for testing\n",
    "n_estimators_options = [100, 200, 300]\n",
    "max_features_options = ['sqrt', 'log2', None]\n",
    "max_depth_options = [10, 15, 20, None]\n",
    "\n",
    "best_score = np.inf\n",
    "\n",
    "# Test all the combinations\n",
    "for n_estimators in n_estimators_options:\n",
    "    for max_features in max_features_options:\n",
    "        for max_depth in max_depth_options:\n",
    "            model = RandomForestRegressor(n_estimators=n_estimators, max_features=max_features, max_depth=max_depth, random_state=42)\n",
    "            model.fit(X_train, y_train)\n",
    "            scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "            mean_mse = -scores.mean()\n",
    "\n",
    "            print(f\"Random Forest with n_estimators={n_estimators}, max_features={max_features}, max_depth={max_depth}: MSE={mean_mse:.2f}\")\n",
    "\n",
    "            # Guardar el mejor modelo\n",
    "            if mean_mse < best_score:\n",
    "                best_score = mean_mse\n",
    "                best_params = {'n_estimators': n_estimators, 'max_features': max_features, 'max_depth': max_depth}\n",
    "\n",
    "print(f\"Best MSE: {best_score:.2f} with parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de Combinaciones de Características con Regresión Lineal\n",
    "Este bloque evalúa diferentes combinaciones de características para predecir las puntuaciones de matemáticas utilizando regresión lineal. Se almacenan los resultados en formato JSON para facilitar su análisis posterior y visualización. La evaluación se realiza hasta un número máximo de características especificado, analizando el error cuadrático medio (MSE) y la comparación entre valores reales y predichos para las mejores combinaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import combinations\n",
    "import json\n",
    "\n",
    "def test_feature_combinations(df, target, max_features=3):\n",
    "    features = [col for col in df.columns if col != target]\n",
    "    results = []\n",
    "\n",
    "        # Create file to store the results \n",
    "    filename = f\"../Results/linear_regression_results_{max_features}_features.json\"\n",
    "    \n",
    "    # Probar todas las combinaciones de características\n",
    "    for r in range(1, max_features + 1):\n",
    "        for subset in combinations(features, r):\n",
    "            X = df[list(subset)]\n",
    "            y = df[target]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            \n",
    "            # Entrenar el modelo de regresión lineal\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train, y_train)\n",
    "            predictions = model.predict(X_test)\n",
    "            mse = mean_squared_error(y_test, predictions)\n",
    "            \n",
    "            # Almacenar el subset, MSE, y una muestra de los valores reales vs. predichos\n",
    "            results.append({\n",
    "                'features': subset,\n",
    "                'mse': mse,\n",
    "                'sample_comparison': {\n",
    "                    'actual': y_test[:5].tolist(),\n",
    "                    'predicted': predictions[:5].tolist()\n",
    "                }\n",
    "            })\n",
    "\n",
    "    # Ordenar los resultados por MSE\n",
    "    results.sort(key=lambda x: x['mse'])\n",
    "\n",
    "    # invert the order to have the best MSE first\n",
    "    results = results[:100][::-1]\n",
    "\n",
    "    # save the results to a file\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(results, file, indent=4)\n",
    "\n",
    "# Ejemplo de uso\n",
    "test_feature_combinations(df_encoded, 'math score', max_features=1)\n",
    "test_feature_combinations(df_encoded, 'math score', max_features=3)\n",
    "test_feature_combinations(df_encoded, 'math score', max_features=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de Combinaciones de Características con Modelo Ridge\n",
    "Este bloque implementa pruebas similares al anterior pero usando el modelo Ridge para considerar la regularización. Se ajustan los datos y se evalúan diferentes valores del hiperparámetro alpha para optimizar el modelo. Los resultados se almacenan en JSON para un análisis detallado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "\n",
    "def test_ridge_combinations(df, target, max_features=3, alpha_options=[0.001, 0.01, 0.1, 1, 10, 100]):\n",
    "    features = [col for col in df.columns if col != target]\n",
    "    results = []\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Create file to store the results \n",
    "    filename = f\"../Results/ridge_results_max_features_{max_features}.json\"\n",
    "\n",
    "    \n",
    "    # Probar todas las combinaciones de características\n",
    "    for r in range(1, max_features + 1):\n",
    "        for subset in combinations(features, r):\n",
    "            X = df[list(subset)]\n",
    "            y = df[target]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            \n",
    "            # Escalar los datos\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            \n",
    "            # Evaluar diferentes alphas\n",
    "            for alpha in alpha_options:\n",
    "                model = Ridge(alpha=alpha, max_iter=10000)\n",
    "                model.fit(X_train_scaled, y_train)\n",
    "                predictions = model.predict(X_test_scaled)\n",
    "                mse = mean_squared_error(y_test, predictions)\n",
    "                scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "                mean_cv_mse = -np.mean(scores)\n",
    "                \n",
    "                # Almacenar los resultados\n",
    "                results.append({\n",
    "                    'features': subset,\n",
    "                    'alpha': alpha,\n",
    "                    'mse': mse,\n",
    "                    'mean_cv_mse': mean_cv_mse,\n",
    "                    'sample_comparison': {\n",
    "                        'actual': y_test[:5].tolist(),\n",
    "                        'predicted': predictions[:5].tolist()\n",
    "                    }\n",
    "                })\n",
    "\n",
    "    \n",
    "    # Ordenar los resultados por MSE de validación cruzada\n",
    "    results.sort(key=lambda x: x['mean_cv_mse'])\n",
    "\n",
    "    results = results[:100][::-1]\n",
    "\n",
    "    # Write the results to the file\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(results, file, indent=4)\n",
    "\n",
    "test_ridge_combinations(df_encoded, 'math score', max_features=2, alpha_options=[0.001, 0.01, 0.1, 1, 10, 100])\n",
    "test_ridge_combinations(df_encoded, 'math score', max_features=3, alpha_options=[0.001, 0.01, 0.1, 1, 10, 100])\n",
    "test_ridge_combinations(df_encoded, 'math score', max_features=5, alpha_options=[0.001, 0.01, 0.1, 1, 10, 100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de Combinaciones de Características con Modelo Random Forest\n",
    "Este bloque examina cómo diferentes configuraciones del modelo Random Forest afectan el rendimiento en la predicción de las puntuaciones de matemáticas. Se prueban varias configuraciones de árboles, características y profundidades para encontrar la combinación óptima, almacenando también los resultados en JSON.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "\n",
    "def test_random_forest_combinations(df, target, max_features_comb=3):\n",
    "    features = [col for col in df.columns if col != target]\n",
    "    results = []\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Crear archivo para almacenar los resultados\n",
    "    filename = f\"../Results/random_forest_results_max_features_{max_features_comb}.json\"\n",
    "\n",
    "    # Opciones de configuración del Random Forest\n",
    "    n_estimators_options = [100, 200]\n",
    "    max_features_options = ['sqrt', 'log2', None]\n",
    "    max_depth_options = [10, 15, None]\n",
    "\n",
    "    # Probar todas las combinaciones de características\n",
    "    for r in range(1, max_features_comb + 1):\n",
    "        for subset in combinations(features, r):\n",
    "            X = df[list(subset)]\n",
    "            y = df[target]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "            # Escalar los datos\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            # Evaluar diferentes configuraciones del Random Forest\n",
    "            for n_estimators in n_estimators_options:\n",
    "                for max_features in max_features_options:\n",
    "                    for max_depth in max_depth_options:\n",
    "                        model = RandomForestRegressor(n_estimators=n_estimators, max_features=max_features, max_depth=max_depth, random_state=42)\n",
    "                        model.fit(X_train_scaled, y_train)\n",
    "                        predictions = model.predict(X_test_scaled)\n",
    "                        mse = mean_squared_error(y_test, predictions)\n",
    "                        scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "                        mean_cv_mse = -np.mean(scores)\n",
    "\n",
    "                        # Almacenar los resultados\n",
    "                        results.append({\n",
    "                            'features': subset,\n",
    "                            'n_estimators': n_estimators,\n",
    "                            'max_features': max_features,\n",
    "                            'max_depth': max_depth,\n",
    "                            'mse': mse,\n",
    "                            'mean_cv_mse': mean_cv_mse,\n",
    "                            'sample_comparison': {\n",
    "                                'actual': y_test[:5].tolist(),\n",
    "                                'predicted': predictions[:5].tolist()\n",
    "                            }\n",
    "                        })\n",
    "\n",
    "    # Ordenar los resultados por MSE de validación cruzada\n",
    "    results.sort(key=lambda x: x['mean_cv_mse'])\n",
    "\n",
    "    results = results[:100][::-1]\n",
    "\n",
    "    # Escribir los resultados en el archivo y mostrar los 20 mejores\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(results, file, indent=4)\n",
    "\n",
    "# Ejemplo de uso\n",
    "test_random_forest_combinations(df_encoded, 'math score', max_features_comb=1)\n",
    "test_random_forest_combinations(df_encoded, 'math score', max_features_comb=2)\n",
    "# test_random_forest_combinations(df_encoded, 'math score', max_features_comb=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de Predicciones vs. Valores Reales\n",
    "Esta función genera un gráfico que compara los valores reales con los valores predichos por los modelos. Es útil para evaluar visualmente la precisión de las predicciones y la adherencia del modelo a la línea de identidad, donde las predicciones perfectas deberían caer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualización de los resultados\n",
    "def plot_predictions_vs_actual(actual, predicted, title):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(actual, predicted, alpha=0.5)\n",
    "    plt.plot([min(actual), max(actual)], [min(actual), max(actual)], '--r')\n",
    "    plt.xlabel('Actual Scores')\n",
    "    plt.ylabel('Predicted Scores')\n",
    "    plt.title('Actual vs. Predicted Scores - ' + title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de Resultados de Modelos Predictivos\n",
    "Este bloque define una función que carga resultados de modelos predictivos desde archivos JSON y visualiza la comparación entre los valores predichos y los valores reales. Esto permite evaluar visualmente la precisión de diferentes modelos y configuraciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "# function to visualize all models\n",
    "def visualize_results(filename, model_name):\n",
    "    with open(filename, 'r') as file:\n",
    "        results = json.load(file)\n",
    "    \n",
    "    first_result = results[0]  # Change this to visualize other results\n",
    "\n",
    "    actual_scores = first_result['sample_comparison']['actual']\n",
    "    predicted_scores = first_result['sample_comparison']['predicted']\n",
    "\n",
    "    # Create plots of predictions vs. actual and residuals\n",
    "    plot_predictions_vs_actual(actual_scores, predicted_scores, model_name)\n",
    "\n",
    "# Visualize the results for the linear regression model with 5 features\n",
    "visualize_results(\"../Results/linear_regression_results_5_features.json\", \"Linear Regression with 5 Features\")\n",
    "\n",
    "# Visualize the results for the Ridge model with 5  features\n",
    "visualize_results(\"../Results/ridge_results_max_features_5.json\", \"Ridge Regression with 5 Features\")\n",
    "\n",
    "# Visualize the results for the Random Forest model with 1 feature\n",
    "visualize_results(\"../Results/random_forest_results_max_features_2.json\", \"Random Forest with 1 Feature\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
